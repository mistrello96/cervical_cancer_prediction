\section{METODI}
A seguito delle operazioni di \textit{preprocessing} del dataset, al fine di confrontare tra loro le varie tecniche di feature reduction, il \textit{workflow} si sviluppa in contemporanea su tre differenti livelli.
Ciascuno di essi gestisce privatamente una copia del dataset preprocessato.
Il primo livello fornisce in input agli algoritmi di apprendimento del modello il dataset senza che abbia subito alcuna operazione di feature reduction.
Il secondo fornisce come input all'algoritmo il risultato di un'operazione di feature extraction applicata al dataset mediante la tecnica della PCA (Principal Component Analysis). Questo approccio permette di trasformare un insieme di variabili correlate tra loro in un insieme ordinato di nuove feature non correlate tra loro; la trasformazione è definita in modo che la prima componente risulti essere quella con maggiore varianza, mentre tutte le successive mostrano il maggior valore di varianza possibile sotto il vincolo di ortogonalità con la precedente.
Al fine di stabilire la dimensionalità dello spazio di feature prodotto dalla PCA, è stato effettuato uno studio preliminare che consiste nella valutazione delle performance dei due algoritmi utilizzati, Decision Tree (DT) e Random Forest (RF), al variare del numero di componenti nell'intervallo $[1, 33]$.\\
Infine, il terzo livello del \textit{workflow} fornisce come input agli algoritmi di apprendimento automatico il dataset a seguito di un'operazione di feature selection mediante l'utilizzo di un filtro basato sulla correlazione; al fine di individuare il threshold di selezione ottimale, è stato prodotto uno studio simile a quello realizzato per la PCA, testando valori i valori nel range [0,05, 0,95] e valutando le performance dei modelli.
La scelta di tale filtro è stata dettata dal fatto che esso risulta appartenere alla classe dei filtri multivariati; ciò permette di individuare sia le feature irrilevanti sia quelle dipendenti tra loro, permettendo così di rimuovere la ridondanza dell'informazione. 
In aggiunta, i risultati evidenziati durante l'esplorazione del dataset (la presenza di feature altamente correlate tra loro) hanno suggerito la scelta di questa strategia, che risulta essere computazionalmente sostenibile dato il numero contenuto di record presenti nel dataset.

Per ogni livello del \textit{workflow} sono stati utilizzati due differenti algoritmi per apprendere i rispettivi modelli; in particolare sono stati impiegati un DT (\texttt{J48}) e una RF.
Gli alberi di decisione sono una classe di tecniche di apprendimento automatico; la struttura è composta da nodi interni che rappresentano test su uno o più attributi, mentre le foglie costituiscono i risultati della decisione. L'algoritmo utilizzato per la creazione di questi alberi è \texttt{J48}, un'implementazione che estende la più classica \texttt{ID3} con il supporto di valori continui degli attributi. Al fine di stabilire quali siano i migliori test da effettuare all'interno dei nodi dell'albero viene valutata l'\textit{information gain}, una misura in grado di evidenziare quali divisioni siano in grado di generare sottogruppo appartenenti a classi ben distinte.
Le random forest sono un modello \textit{ensamble} costituito da un insieme predefinito di alberi di decisione. Ogni albero viene addestrato su un sottoinsieme di record e feature. Al momento della presentazione di un sample da classificare, ogni albero che compone la foresta propone la sua classificazione, che è poi valutata in modo pesato insieme a tutte le altre al fine di fornire una predizione complessiva.
Per confrontare le performance medie dei modelli derivanti dagli algoritmi appena presentati è stato sfruttato un processo di 5-fold \textit{stratified cross-validation}.
La scelta di utilizzare una tecnica di \textit{cross-validation} stratificata (SCV) è stata dettata dalla natura estremamente sbilanciata del problema, che ha portato altresì alla scelta di utilizzare un numero di fold contenuto, paria a $5$, in modo da mantenere in ogni fold un numero ragionevole di esempi della classe minoritaria.
Data la scarsa rappresentazione della classe positiva presente nei vari train set, alla SCV è stata affiancata un'operazione di \textit{over-sampling} della classe minoritaria mediante la tecnica SMOTE (Synthetic Minority Over-sampling TEchnique). 
Questa tecnica permette di generare dei sample sintetici della classe minoritaria mediante la seguente procedura: seleziona un campione della classe in minoranza; considera quindi i \textit{k-nearest neighbors} del punto selezionato, crea un vettore tra il punto corrente e uno dei vicini scelto a caso e varia il valore del vettore degli attributi moltiplicandoli per uno scalare nell'intervallo $[0, 1]$.
L'operazione è stata effettuata esclusivamente sulla porzione di train di ogni iterazione della SCV, in modo da garantire che le performance misurate sul test set non fossero in alcuno modo influenzate.
L'utilizzo di una tecnica come SMOTE ha permesso di bilanciare le classi nei dati di training, permettendo così al modello di apprendere in modo più soddisfacente; è stato preferito l'\textit{over-sampling} all'\textit{under-sampling} in quanto quest'ultimo avrebbe ridotto drasticamente le dimensioni del train set, minando così le possibilità di apprendimento.
Si fa notare che il \textit{seed} per la generazione casuale dei fold è stato fissato a favore della ripetibilità dell'esperimento; tale \textit{seed} è inoltre condiviso tra tutti i generatori, in modo che vengano utilizzati i medesimi fold nei vari livelli del \textit{workflow}.
Al fine di stabilire se l'utilizzo da tale tecnica producesse un'alterazione delle performance nei modelli considerati, una verifica qualitativa è stata eseguita sui risultati degli algoritmi addestrati sull'intero dataset in presenza ed in assenza della tecnica di \textit{oversampling}.
Al termine delle operazioni di \textit{cross-validation}, i modelli prodotti dagli algoritmi sono stati confrontati tra loro basandosi sulla misura f1-\textit{score} della classe minoritaria (\textit{i.e.}, presenza di cancro), calcolata come \[2 * \frac{precision*recall}{precision+recall}.\]
L'utilizzo di una metrica come l'accuratezza o l'errore non s'addice al problema affrontato in quanto, considerato l'elevato grado di sbilanciamento del problema, un classificatore \textit{baseline} che predica esclusivamente la non presenza del tumore avrebbe ottenuto un'accuratezza molto elevata, pur non servendo allo scopo del lavoro. 
Si è invece scelto di utilizzare come misura di performance l'f1-\textit{score} perché in un problema di questo tipo è stato ritenuto importante considerare sia la \textit{precision}, ovvero la percentuale di veri positivi individuati rispetto al totale di predizioni positive fatte, che la \textit{recall}, ovvero il numero di veri positivi individuati rispetto al numero totale che andava individuato. 
La motivazione alla base di questa decisione risulta essere chiara: si vorrebbero individuare correttamente il maggior numero possibile di soggetti affetti dalla patologia, mentre, al contempo, si vorrebbe evitare di diagnosticare erroneamente a molti pazienti di essere malati di cancro e costringerli così a dover affrontare ulteriori esami e operazioni invasive e costose; si è quindi optato per la medie armonica delle due metriche sopracitate (\textit{i.e.}, f1-\textit{score}), in modo da bilanciare i falsi positivi con i falsi negativi.
Un incontro con esperti del dominio medico potrebbe portare ad un cambio della misura di performance utilizzata, prediligendo una delle due componenti dell'f1-\textit{score} a discapito dell'altra; l'introduzione di una matrice dei costi che stimi il differente impatto economico e umano di falsi positivi e negativi potrebbe rivelarsi particolarmente utile in questo senso.\\
I confronti fra i vari modelli sono stati effettuati valutando la differenza tra la medie degli \textit{score} prodotti durante le varie iterazioni della \textit{cross-validation}; per stabilire se tale differenza fosse statisticamente significativa o meno sono stati utilizzati dei \textit{paired} t-test con un livello di confidenza pari a 0.95. Il test \textit{paired} è stato preferito alla versione \textit{unpaired} in quanto le performance dei vari modelli derivano i medesimi fold del processo di SCV.
Successivamente, sono stati confrontati fra loro i modelli ritenuti migliori per ogni livello (se sono risultati statisticamente differenti, altrimenti ne è stato selezionato uno a piacere), andando a verificare la presenza di un modello che risulti statisticamente migliore rispetto agli altri; anche questi test sono stati effettuati con un \textit{paired} t-test, con un valore di confidenza fissato a 0.95.

Infine, sono state valutate le performance di una RF in assenza di alcune feature derivanti da esami invasivi e costosi che, soprattutto in paesi di via di sviluppo, non risultano sempre disponibili o di facile accesso.
In particolare, dal dataset ottenuto a seguito della fase di \textit{preprocessing}, sono state rimosse le seguenti feature: \textit{Hinselmann} (cioè la colposcopia), \textit{Schiller} (test eseguito durante la colposcopia) e \textit{Citology} (osservazione al microscopio di cellule ottenute mediante il Pap test o altre tecniche).
Questo dataset è stato, quindi, utilizzato per l'esecuzione dell'algoritmo all'interno di una 5-fold \textit{stratified cross-validation} nelle stesse condizioni sperimentali presentate in precedenza.