\section{METODI}
\todo[inline]{controlla se ho messo numeri giusti, mi da errori quando carico il workflow di knime. please DP}
Dopo le operazioni di \textit{preprocessing} del dataset, al fine di confrontare tra loro le varie tecniche di feature reduction, il \textit{workflow} si sviluppa in contemporanea su tre differenti livelli.
Ciascuno di essi gestisce privatamente una copia del dataset preprocessato.
Il primo livello fornisce in input agli algoritmi di apprendimento del modello il dataset senza che abbia subito alcuna operazione di feature reduction.
Il secondo fornisce come input il risultato di un'operazione di feature extraction applicata sul dataset mediante la tecnica della PCA (Principal Component Analysis).
Al fine di stabilire la dimensionalità dello spazio di feature prodotto dalla PCA, è stato effettuato uno studio preliminare il quale consiste nel valutare le performance dei due algoritmi utilizzati (DT e RF) \todo{Se non citate prima mettere significato} tutte le dimensioni nell'intervallo $[1, 33]$.
A seguito di questa analisi, la dimensione ottimale utilizzata è pari a 12, come suggerito dai risultati riportati in Figura \ref{fig:pca-perf}.
Infine, il terzo livello fornisce come input agli algoritmi il dataset dopo un'operazione di feature selection basata su correlazione \todo[inline]{Per allungare il brodo potremmo fare uno studio al variare del threshold della fs come variano le performance? DP} con la soglia di rimozione di feature pari a 0.85 \todo{non ho idea di come chiamarla}.
La scelta di tale stategia è stata dettata dal fatto che è multivariata, di conseguenza, le relazioni tra le differenti feature vengono considerate. 
In aggiunta, i risultati evidenziati durante l'esplorazione del dataset (la presenza di feature altamente correlate tra loro) hanno favorito la scelta di questa strategia, che risulta essere anche computazionalmente efficiente.

Per ogni livello, sono stati utilizzati due algrotimi per apprendere i rispettivi modelli, in particolare, un DT e una RF sono stati utilizzati.
Per confrontare tali algoritmi, \todo[inline]{il modello è quello che deriva dall'algoritmo, in una 5 fold ho di fatto 5 modelli, ma noi confrontiamo gli algo corretto? Dobbiamo essere molto attenti alla nomenclatura DP} si è sfruttato un processo di 5-fold \textit{stratified cross-validation} con un'operazione di \textit{over-sampling} mediante la tecnica SMOTE (Synthetic Minority Over-sampling TEchnique) per quanto concerne la parte di training per la \textit{k}-esima iterazione.
La scelta di utilizzare una tecnica di \textit{cross-validation} stratificata è dettata dalla natura estremamente sbilanciata del problema, per questo analogo motivo si è deciso di utilizzare 5 fold in modo da avere per ogni fold un numero ragionevole di esempi non sintetici della classe minoritaria.
Inoltre, SMOTE è stato impiegato per bilanciare le classi nei dati di training in modo da permettere al modello di apprendere meglio; è stato preferito l'\textit{over-sampling} all'\textit{under-sampling} poiché quest'ultimo avrebbe ridotto notevolmente le dimensioni del train set, inficiando sulle possibilità di apprendimento.
Si fa presente che il \textit{seed} per la generazione randomica dei fold è stato fissato a favore della ripetibilità dell'esperimento, tale \textit{seed} è inoltre condiviso tra tutti i generatori in modo che vengano utilizzati gli stessi fold nei vari livelli.
Al termine delle operazioni di \textit{cross-validation}, per ogni livello i modelli prodotti dagli algoritmi sono stati confrontati tra loro basandosi sulla f1-\textit{score} della classe minoritaria (\textit{i.e.}, presenza di cancro).
Si è scelto di utilizzare come metrica l'f1-\textit{score} perché in un problema del genere si è ritenuto importante sia la metrica di \textit{precision}, ovvero la percentuale di veri positivi individuati rispetto al totale di predizioni positive fatte, sia la \textit{recall}, ovvero il numero di veri positivi individuati rispetto al numero totale che andava individuato. \todo[inline]{mi sento male  a scrivere ciò in un report da 2 Magistrale, ma alcuni dei suoi lavori ritenuti buoni lo hanno fatto. Ergo mi sento di doverlo fare. Libero di aggiungere brodo o siegare cos'è una confusion matrix, io mi rifiuto. DP}
La motivazione è che, chiaramente, si vorrebbero individuare tutti i possibili soggetti affetti dalla patologia, al contempo, però, si vorrebbe evitare di dire a tutti i pazienti di essere malati e portarli a dover affrontare ulteriori esami e operazioni ancora più invasivi; si è quindi optato per la medie armonica delle due metriche sopracitate (\textit{i.e.}, f1-\textit{score}).
Tali confronti sono stati effettuati valutando la differenza tra la medie degli \textit{score} prodotti durante le varie iterazioni della \textit{cross-validation}; per stabilire se tale differenza fosse significativa o meno sono stati utilizzati dei \textit{paired} t-test con un livello di confidenza pari a 0.95, è stato utilizzato un test \textit{paired} perché le metriche derivano dagli stessi fold.\\
Successivamente, si confrontano i modelli ritenuti migliori per ogni livello (se sono risultati statisticamente differenti, altrimenti se ne sceglie uno a piacere) tra loro, andando a stabilire se esiste un modello che è statisticamente migliore degli altri, tali test sono stati effettuati con un \textit{paired} t-test con un valore di confidenza sempre pari a 0.95.

Infine, si è provato valutare le performance di una RF in assenza di alcune feature derivanti da esami invasivi e costosi, i quali, soprattutto in paesi di via di sviluppo, non risulta sempre possibile effettuarli.
In particolare, dal dataset ottenuto dopo la fase di preprocessing, sono state rimosse le seguenti feature: \textit{Hinselmann} (cioè la colposcopia), \textit{Schiller} (test eseguito durante la colposcopia) e \textit{Citology} (osservazione di cellule, ottenute con il Pap test o altre tecniche, al microscopio).
Questo dataset è stato, quindi, utilizzato per l'esecuzione dell'algoritmo all'interno di una 5-fold \textit{cross-validation} con le stesse condizioni sperimentali utilizzate precedentemente.