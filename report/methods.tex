\section{METODI}
\todo[inline]{controlla se ho messo numeri giusti, mi da errori quando carico il workflow di knime. please DP}
A seguito delle operazioni di \textit{preprocessing} del dataset, al fine di confrontare tra loro le varie tecniche di feature reduction, il \textit{workflow} si sviluppa in contemporanea su tre differenti livelli.
Ciascuno di essi gestisce privatamente una copia del dataset preprocessato.
Il primo livello fornisce in input agli algoritmi di apprendimento del modello il dataset senza che abbia subito alcuna operazione di feature reduction.
Il secondo fornisce come input all'algoritmo il risultato di un'operazione di feature extraction applicata al dataset mediante la tecnica della PCA (Principal Component Analysis). Questo approccio permette di trasformare un insieme di variabili correlate tra loro in un insieme ordinato di nuove feature non correlate tra loro; la trasformazione è definita in modo che la prima componente risulti essere quella con maggiore varianza, mentre tutte le successive mostrano il maggior valore di varianza possibile sotto il vincolo di ortogonalità con la precedente.
Al fine di stabilire la dimensionalità dello spazio di feature prodotto dalla PCA, è stato effettuato uno studio preliminare che consiste nella valutazione delle performance dei due algoritmi utilizzati (DT e RF) \todo{Se non citate prima mettere significato} al variare del numero di componenti nell'intervallo $[1, 33]$.\\
Infine, il terzo livello del \textit{workflow} fornisce come input agli algoritmi di apprendimento automatico il dataset a seguito di un'operazione di feature selection mediante l'utilizzo di un filtro basato sulla correlazione; in particolare, gli attributi con una correlazione superiore a 0.85 sono stati rimossi. \todo[inline]{Per allungare il brodo potremmo fare uno studio al variare del threshold della fs come variano le performance? DP Più che altro è un incubo su knime visto come gestisce la cosa, ma si potrebbe fare, sembra interessante}
La scelta di tale filtro è stata dettata dal fatto che esso risulta appartenere alla classe dei filtri multivariati; ciò permette di individuare sia le feature irrilevanti sia quelle dipendenti tra loro, permettendo così di rimuovere la ridondanza dell'informazione. 
In aggiunta, i risultati evidenziati durante l'esplorazione del dataset (la presenza di feature altamente correlate tra loro) hanno suggerito la scelta di questa strategia, che risulta essere computazionalmente sostenibile dato il numero contenuto di record presenti nel dataset.

Per ogni livello del \textit{workflow} sono stati utilizzati due differenti algoritmi per apprendere i rispettivi modelli; in particolare sono stati impiegati un DT e una RF.
Per confrontare tali algoritmi \todo[inline]{il modello è quello che deriva dall'algoritmo, in una 5 fold ho di fatto 5 modelli, ma noi confrontiamo gli algo corretto? Dobbiamo essere molto attenti alla nomenclatura DP} è stato sfruttato un processo di 5-fold \textit{stratified cross-validation}.
La scelta di utilizzare una tecnica di \textit{cross-validation} stratificata (SCV) è stata dettata dalla natura estremamente sbilanciata del problema, che ha portato altresì alla scelta di utilizzare un numero di fold contenuto, paria a $5$, in modo da mantenere in ogni fold un numero ragionevole di esempi della classe minoritaria.
Data la scarsa rappresentazione della classe positiva presente nei vari train set, alla SCV è stata affiancata un'operazione di \textit{over-sampling} della classe minoritaria mediante la tecnica SMOTE (Synthetic Minority Over-sampling TEchnique). 
Questa tecnica permette di generare dei sample sintetici della classe minoritaria; gli attributi di ogni punto sintetico sono generati osservando i \textit{k nearest neighbors} di un sample e, dopo averne selezionato uno, il valore degli attributi è scelto casualmente nel range fissato dal valore dei due punti considerati.\todo{spiegare meglio, magari con una immagine}
L'operazione è stata effettuata esclusivamente sulla porzione di train di ogni iterazione della SCV, in modo da garantire che le performance misurate sul test set non fossero in alcuno modo influenzate.
L'utilizzo di una tecnica come SMOTE ha permesso di bilanciare le classi nei dati di training, permettendo così al modello di apprendere in modo più soddisfacente; è stato preferito l'\textit{over-sampling} all'\textit{under-sampling} in quanto quest'ultimo avrebbe ridotto drasticamente le dimensioni del train set, minando così le possibilità di apprendimento.
Si fa notare che il \textit{seed} per la generazione randomica dei fold è stato fissato a favore della ripetibilità dell'esperimento; tale \textit{seed} è inoltre condiviso tra tutti i generatori, in modo che vengano utilizzati i medesimi fold nei vari livelli del \textit{workflow}.
Al termine delle operazioni di \textit{cross-validation}, i modelli prodotti dagli algoritmi sono stati confrontati tra loro basandosi sulla misura f1-\textit{score} della classe minoritaria (\textit{i.e.}, presenza di cancro).
Si è scelto di utilizzare come metrica l'f1-\textit{score} perché in un problema del genere è stato ritenuto importante considerare sia la metrica di \textit{precision}, ovvero la percentuale di veri positivi individuati rispetto al totale di predizioni positive fatte, che la \textit{recall}, ovvero il numero di veri positivi individuati rispetto al numero totale che andava individuato. 
La motivazione alla base di questa decisione risulta essere chiara: si vorrebbero individuare correttamente il maggior numero possibile di soggetti affetti dalla patologia, mentre, al contempo, si vorrebbe evitare di diagnosticare erroneamente a molti pazienti di essere malati di cancro e costringerli così a dover affrontare ulteriori esami e operazioni invasive e costose; si è quindi optato per la medie armonica delle due metriche sopracitate (\textit{i.e.}, f1-\textit{score}), in modo da bilanciare i falsi positivi con i falsi negativi.
Un incontro con esperti del dominio medico potrebbe portare ad un cambio della misura di performance utilizzata, prediligendo una delle due componenti dell'f1-\textit{score} a discapito dell'altro; l'introduzione di una matrice dei costi che stimi il differente impatto economico e umano di falsi positivi e negativi potrebbe rivelarsi particolarmente utile in questo senso.\\
I confronti fra i vari modelli sono stati effettuati valutando la differenza tra la medie degli \textit{score} prodotti durante le varie iterazioni della \textit{cross-validation}; per stabilire se tale differenza fosse statisticamente significativa o meno sono stati utilizzati dei \textit{paired} t-test con un livello di confidenza pari a 0.95. Il test \textit{paired} è stato preferito alla versione \textit{unpaired} in quanto le performance dei vari modelli derivano i medesimi fold del processo di SCV.
Successivamente, sono stati confrontati fra loro i modelli ritenuti migliori per ogni livello (se sono risultati statisticamente differenti, altrimenti ne è stato selezionato uno a piacere), andando a verificare la presenza di un modello che risulti statisticamente migliore rispetto agli altri; anche questi test sono stati effettuati con un \textit{paired} t-test, con un valore di confidenza fissato a 0.95.

Infine, sono state valutate le performance di una RF in assenza di alcune feature derivanti da esami invasivi e costosi che, soprattutto in paesi di via di sviluppo, non risultano sempre disponibili o di facile accesso.
In particolare, dal dataset ottenuto a seguito della fase di preprocessing, sono state rimosse le seguenti feature: \textit{Hinselmann} (cioè la colposcopia), \textit{Schiller} (test eseguito durante la colposcopia) e \textit{Citology} (osservazione  al microscopio di cellule ottenute mediante il Pap test o altre tecniche).
Questo dataset è stato, quindi, utilizzato per l'esecuzione dell'algoritmo all'interno di una \textit{stratified 5-fold cross-validation} nelle stesse condizioni sperimentali presentate in precedenza.