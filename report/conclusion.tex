\section{CONCLUSIONI E SVILUPPI FUTURI}
Nel lavoro appena presentato è stato analizzato un dataset derivante dai dati di $858$ pazienti di un ospedale di Caracas che si sono sottoposte ad approfondimenti per la prevenzione del tumore alla cervice uterina.
Dopo aver eseguito analisi esplorative del dataset, che hanno mostrato un forte sbilanciamento dei sample verso la non presenza del tumore, il dataset è stato sottoposto a operazioni di \textit{cleaning} e \textit{preprocessing}, rimuovendo due feature (a causa della scarsa rappresentazione nei record) e effettuando operazioni di imputazioni sui molti \textit{missing values} presenti nel dataset.
A seguito della rimozione degli outlier, sono state eseguite analisi esplorative dei record che presentavano biopsia positiva, analizzando la distribuzione dei fattori di rischio noti in letteratura.
L'analisi effettuata ha in parte confermato le informazioni apprese sulla malattia, evidenziando un range di età compatibile e una possibile relazione tra malattie sessualmente trasmissibili e lo sviluppo di questa forma di cancro.
L'analisi della correlazione tra le feature ha evidenziato valori elevati per molte di esse.\\
Terminate le operazioni di \textit{preprocessing} sul dataset, sono stati utilizzati due differenti algoritmi di apprendimento automatico, decision tree e random forest, per effettuare la classificazione dei record.
Al fine di stabilire se una tecnica di feature reduction potesse portare beneficio al processo di addestramento degli algoritmi, sono state realizzate tre differenti pipeline parallele; la prima utilizza l'intero dataset, la seconda applica una PCA e la terza un filtro che sfrutta la correlazione.
Il numero di componenti della PCA e il threshold del filtro sono stati stabiliti mediante un'indagine delle performance dei modelli a seguito della variazione di questi valori.
Stabiliti gli iperparametri ottimali per le tecniche di riduzione della dimensionalità, gli algoritmi sono stati addestrati in un processo di 5-fold \textit{startified cross-validation}, utilizzando SMOTE come tecnica di \textit{oversampling} sulla porzione di train del dataset.
L'utilizzo di tale tecnica è motivato da un'analisi qualitativa che ha mostrato un non peggioramento delle performance degli algoritmi, con miglioramenti in alcuni casi.
I risultati delle random forest hanno mostrato performance medie leggermente superiori rispetto ai rispettivi alberi, ma i test di significatività non hanno rilevato una differenza statisticamente significativa (fatta eccezione per i modelli con in input il dataset ridotto tramite filtro). Anche un confronto tra modelli con input differenti non ha evidenziato una differenza significativa tra le medie.
Infine, è stato effettuato un tentativo di addestrare gli algoritmi precedenti in assenza delle feature relative agli esami clinici effettuati sulle pazienti. Le performance ottenute hanno mostrato un drastico deterioramento, confermando la necessità di queste analisi al fine di un corretto riconoscimento della patologia.
Concludendo, è possibile affermare che gli obiettivi posti all'inizio di questo lavoro siano stati raggiunti, anche se i test statistici non hanno evidenziato con chiarezza la superiorità di uno tra i vari approcci proposti.
Al fine si superare questo problema, in futuro sarebbe necessario raccogliere dati su una popolazione sensibilmente più ampia, in modo da non essere più limitati dalla scarsa rappresentazione di record che presentano la patologia e rendendo altresì più significative le analisi effettuate e più robusti i modelli proposti.
Lo sviluppo di una pipeline per l'imputazione dei \textit{missing value} che tenga in considerazione i legami e le relazioni tra le varie feature potrebbe garantire un ulteriore margine di miglioramento, assicurando la consistenza di alcuni vincoli logici che andrebbero altrimenti persi con le classiche tecniche di imputazione.
Un ulteriore punto di sviluppo di questo lavoro potrebbe scaturire dal confronto con esperti del dominio medico, grazie ai quali si potrebbe ottenere una stima più accurata del peso/costo dei diversi tipi di predizioni errate dei modelli, ottimizzandoli così secondo i nuovi criteri proposti.

\section*{NOTE TECNICHE}
Si segnala per questioni di compatibilità che la versione di Knime utilizzata per l'esecuzione del workflow relativo al lavoro svolto è la 4.1.0, con integrazione Python per l'esecuzione di snippet grafici e Weka per la creazione di alcuni modelli di predizione.
Al fine del corretto funzionamento del workflow, è necessario inserire il dataset ottenuto da \cite{ML} nella radice del workspace del progetto e creare una cartella denominata images, nella quale verranno salvati i grafici prodotti dal workflow.
La repository del progetto è disponibile all'indirizzo\\\url{https://gitlab.com/mistrello96/cervical_cancer_prediction}